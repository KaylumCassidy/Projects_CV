{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fYCGnOBYu_sZ",
        "Eit-zZv6wGrO",
        "_QxXPPcuwdIs",
        "j9F079xRzHFn",
        "sZUn71C-06LM",
        "2m7yZ0NGzr8i",
        "v3MiPcDjzuA-",
        "HHBK-xMw0S5-",
        "TD-auwWP0eVS",
        "hUWF2E5a4toe",
        "s2DPqLxE-IpX",
        "hNmhJ_QpsvP5",
        "7Z6QDMlPiQ2Z",
        "gEWQrpx3hDvd",
        "rM6zLC6Ohniv",
        "8nL8UGCLiI9x",
        "EAs_7hK_i2m5",
        "oGRYKknUjJP2",
        "GJDk4CZk_vhb",
        "rB9lYvPs8MV3",
        "YNudVPa-pN1o",
        "2ycwroy7qa02",
        "oS8MZ2mcsYDj",
        "H9po0Fu0qWKm"
      ],
      "authorship_tag": "ABX9TyNU9xhlIMB5nVCxTjtX5Qz0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KaylumCassidy/Projects_CV/blob/main/C20323831_CA2_SF_KAYLUM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use a Big Data Framework PySpark Video game dateset"
      ],
      "metadata": {
        "id": "Ue7-_pCguxD0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Installing PySpark in Google Colab"
      ],
      "metadata": {
        "id": "fYCGnOBYu_sZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "QxHtkyOjuvxW",
        "outputId": "d7ff02e9-3dac-494a-bb22-9791d70cdb1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Waiting for headers] [W\u001b[0m\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "tar: spark-3.2.1-bin-hadoop3.2.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n",
            "Collecting pyspark\n",
            "  Using cached pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=8545fd7c5f9235fd6a19f6877f08160aefa7ec45d0fe8d6784bd5e5f99b57648\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (0.10.9.7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7a6a2808f0d0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6330f596b518:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Our First Spark Example</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#Check this site for the latest download link https://www.apache.org/dyn/closer.lua/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "!pip install pyspark\n",
        "!pip install py4j\n",
        "\n",
        "import os\n",
        "import sys\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "# os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()\n",
        "\n",
        "import pyspark\n",
        "\n",
        "from pyspark.sql import DataFrame, SparkSession\n",
        "from typing import List\n",
        "import pyspark.sql.types as T\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark= SparkSession \\\n",
        "       .builder \\\n",
        "       .appName(\"Our First Spark Example\") \\\n",
        "       .getOrCreate()\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Reading Data"
      ],
      "metadata": {
        "id": "Eit-zZv6wGrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "path = \"https://raw.githubusercontent.com/KaylumCassidy/CA/main/vgsales.csv\"\n",
        "req = requests.get(path)\n",
        "url_content = req.content\n",
        "\n",
        "csv_file_name = 'video_game_sale.csv'\n",
        "csv_file = open(csv_file_name, 'wb')\n",
        "\n",
        "csv_file.write(url_content)\n",
        "csv_file.close()\n",
        "\n",
        "df = spark.read.csv('/content/'+csv_file_name, header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "9F9wHlRdwCnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PySpark DataFrames"
      ],
      "metadata": {
        "id": "_QxXPPcuwdIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Viewing the dataframe schema\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6jEOR7pwaKC",
        "outputId": "fc898ee5-38f7-4c63-dea9-56970e3e3181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Rank: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Platform: string (nullable = true)\n",
            " |-- Year: string (nullable = true)\n",
            " |-- Genre: string (nullable = true)\n",
            " |-- Publisher: string (nullable = true)\n",
            " |-- NA_Sales: double (nullable = true)\n",
            " |-- EU_Sales: double (nullable = true)\n",
            " |-- JP_Sales: double (nullable = true)\n",
            " |-- Other_Sales: double (nullable = true)\n",
            " |-- Global_Sales: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "\n",
        "\n",
        "# Convert \"Year\" column from string to integer\n",
        "df = df.withColumn(\"Year\", col(\"Year\").cast(IntegerType()))\n",
        "df = df.withColumn(\"NA_Sales\", col(\"NA_Sales\").cast(IntegerType()))\n",
        "df = df.withColumn(\"EU_Sales\", col(\"EU_Sales\").cast(IntegerType()))\n",
        "df = df.withColumn(\"JP_Sales\", col(\"JP_Sales\").cast(IntegerType()))\n",
        "df = df.withColumn(\"Other_Sales\", col(\"Other_Sales\").cast(IntegerType()))\n",
        "df = df.withColumn(\"Global_Sales\", col(\"Global_Sales\").cast(IntegerType()))"
      ],
      "metadata": {
        "id": "E7ffexKAyMqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary stats\n",
        "df.describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwchBprQxZBg",
        "outputId": "2f765409-fe2d-4d6a-a75b-056f2ca9c9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------------+--------------------+--------+------------------+--------+---------------+-------------------+------------------+-------------------+--------------------+------------------+\n",
            "|summary|             Rank|                Name|Platform|              Year|   Genre|      Publisher|           NA_Sales|          EU_Sales|           JP_Sales|         Other_Sales|      Global_Sales|\n",
            "+-------+-----------------+--------------------+--------+------------------+--------+---------------+-------------------+------------------+-------------------+--------------------+------------------+\n",
            "|  count|            16598|               16598|   16598|             16327|   16598|          16598|              16598|             16598|              16598|               16598|             16598|\n",
            "|   mean|8300.605253645017|              1942.0|  2600.0|2006.4064433147546|    NULL|           NULL|0.26466742981084057|0.1466520062658483|0.07778166044101108|0.048063019640913515|  0.53744065550074|\n",
            "| stddev|  4791.8539328964|                NULL|     0.0| 5.828981114713253|    NULL|           NULL| 0.8166830292988798|0.5053512312869136| 0.3092906480822022| 0.18858840291271395|1.5550279355699066|\n",
            "|    min|                1|         '98 Koshien|    2600|              1980|  Action|10TACLE Studios|                0.0|               0.0|                0.0|                 0.0|              0.01|\n",
            "|    max|            16600|¡Shin Chan Flipa ...|    XOne|              2020|Strategy|   responDESIGN|              41.49|             29.02|              10.22|               10.57|             82.74|\n",
            "+-------+-----------------+--------------------+--------+------------------+--------+---------------+-------------------+------------------+-------------------+--------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where Platform is \"PS2\" and order by \"Year\" descending\n",
        "df_filtered = df.filter(df.Platform == \"PS2\").orderBy(col(\"Year\").desc())\n",
        "\n",
        "# Show the results\n",
        "df_filtered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYBW5GJOxgsy",
        "outputId": "b8eaf5a9-7920-4185-86a9-20e8cefe86f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------------+--------+----+---------+--------------------+--------+--------+--------+-----------+------------+\n",
            "| Rank|                Name|Platform|Year|    Genre|           Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|\n",
            "+-----+--------------------+--------+----+---------+--------------------+--------+--------+--------+-----------+------------+\n",
            "| 9396|    MLB 11: The Show|     PS2|2011|   Sports|Sony Computer Ent...|    0.06|    0.05|     0.0|       0.02|        0.13|\n",
            "|10141|       WWE All Stars|     PS2|2011| Fighting|                 THQ|    0.05|    0.04|     0.0|       0.01|        0.11|\n",
            "|11226|             FIFA 12|     PS2|2011|   Sports|     Electronic Arts|     0.0|    0.02|     0.0|       0.06|        0.09|\n",
            "|12491|Pro Evolution Soc...|     PS2|2011|   Action|Konami Digital En...|     0.0|     0.0|    0.06|        0.0|        0.06|\n",
            "|13201|Major League Base...|     PS2|2011|   Sports|Take-Two Interactive|    0.02|    0.02|     0.0|       0.01|        0.05|\n",
            "|15296|Moujuutsukai to O...|     PS2|2011|Adventure|        Idea Factory|     0.0|     0.0|    0.02|        0.0|        0.02|\n",
            "|16059|Sangoku Koi Senki...|     PS2|2011|Adventure|           Prototype|     0.0|     0.0|    0.01|        0.0|        0.01|\n",
            "| 7165|Ben 10 Ultimate A...|     PS2|2010| Platform|         D3Publisher|    0.13|    0.06|     0.0|       0.04|        0.22|\n",
            "| 3995|       Madden NFL 11|     PS2|2010|   Sports|     Electronic Arts|    0.41|    0.02|     0.0|       0.07|         0.5|\n",
            "| 6390|Scooby-Doo! and t...|     PS2|2010|   Action|Warner Bros. Inte...|    0.08|    0.11|     0.0|       0.08|        0.27|\n",
            "| 2711|      FIFA Soccer 11|     PS2|2010|   Sports|     Electronic Arts|    0.11|    0.29|     0.0|       0.36|        0.76|\n",
            "| 5072|WWE SmackDown vs....|     PS2|2010| Fighting|                 THQ|    0.24|    0.07|     0.0|       0.07|        0.38|\n",
            "|10426|Pro Yaky? Spirits...|     PS2|2010|   Sports|Konami Digital En...|     0.0|     0.0|     0.1|        0.0|         0.1|\n",
            "|12193|Lucian Bee's: Jus...|     PS2|2010|Adventure|                 5pb|     0.0|     0.0|    0.07|        0.0|        0.07|\n",
            "|14404|   Kiniro no Corda 3|     PS2|2010|Adventure|          Tecmo Koei|     0.0|     0.0|    0.03|        0.0|        0.03|\n",
            "| 4687|pro evolution soc...|     PS2|2010|   Sports|Konami Digital En...|    0.04|    0.21|    0.05|       0.11|        0.41|\n",
            "| 7051|Major League Base...|     PS2|2010|   Sports|Take-Two Interactive|    0.11|    0.09|     0.0|       0.03|        0.23|\n",
            "|12647|Syphon Filter: Lo...|     PS2|2010|  Shooter|Sony Computer Ent...|    0.03|    0.02|     0.0|       0.01|        0.06|\n",
            "| 5025|    NCAA Football 11|     PS2|2010|   Sports|     Electronic Arts|    0.19|    0.15|     0.0|       0.05|        0.38|\n",
            "|12760|The Lord of the R...|     PS2|2010|   Action|Warner Bros. Inte...|    0.03|    0.02|     0.0|       0.01|        0.06|\n",
            "+-----+--------------------+--------+----+---------+--------------------+--------+--------+--------+-----------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple Group by Function\n",
        "df.groupBy(\"Platform\").sum(\"NA_Sales\").orderBy(F.desc(\"sum(NA_Sales)\")).show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS7inQ9LybyZ",
        "outputId": "4455a986-538b-493b-8957-00efd8f6d46d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "|Platform|sum(NA_Sales)     |\n",
            "+--------+------------------+\n",
            "|X360    |601.0499999999992 |\n",
            "|PS2     |583.8399999999925 |\n",
            "|Wii     |507.7099999999991 |\n",
            "|PS3     |392.2599999999998 |\n",
            "|DS      |390.7099999999977 |\n",
            "|PS      |336.509999999998  |\n",
            "|GBA     |187.54000000000033|\n",
            "|XB      |186.6900000000008 |\n",
            "|N64     |139.02000000000015|\n",
            "|GC      |133.46000000000004|\n",
            "|NES     |125.94000000000005|\n",
            "|GB      |114.32000000000001|\n",
            "|PSP     |108.98999999999975|\n",
            "|PS4     |96.79999999999998 |\n",
            "|PC      |93.2800000000005  |\n",
            "|2600    |90.59999999999992 |\n",
            "|XOne    |83.19000000000003 |\n",
            "|3DS     |78.86999999999996 |\n",
            "|SNES    |61.22999999999998 |\n",
            "|WiiU    |38.31999999999999 |\n",
            "+--------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Spark SQL"
      ],
      "metadata": {
        "id": "j9F079xRzHFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a table from the dataframe\n",
        "df.createOrReplaceTempView(\"Year\") #temporary view\n",
        "# df.saveAsTable(\"Year\") #Save as a table\n",
        "# df.write.mode(\"overwrite\").saveAsTable(\"Year\") #Save as table and overwrite table if exits"
      ],
      "metadata": {
        "id": "iqDzkXsQzJLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df2 = spark.sql(\"SELECT * from Year\")\n",
        "df2.printSchema()\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-lCCbPHzQRt",
        "outputId": "6b6f6771-95ab-4297-b6f9-54f47d53bc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Rank: integer (nullable = true)\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Platform: string (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Genre: string (nullable = true)\n",
            " |-- Publisher: string (nullable = true)\n",
            " |-- NA_Sales: double (nullable = true)\n",
            " |-- EU_Sales: double (nullable = true)\n",
            " |-- JP_Sales: double (nullable = true)\n",
            " |-- Other_Sales: double (nullable = true)\n",
            " |-- Global_Sales: double (nullable = true)\n",
            "\n",
            "+----+--------------------+--------+----+------------+--------------------+--------+--------+--------+-----------+------------+\n",
            "|Rank|                Name|Platform|Year|       Genre|           Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|\n",
            "+----+--------------------+--------+----+------------+--------------------+--------+--------+--------+-----------+------------+\n",
            "|   1|          Wii Sports|     Wii|2006|      Sports|            Nintendo|   41.49|   29.02|    3.77|       8.46|       82.74|\n",
            "|   2|   Super Mario Bros.|     NES|1985|    Platform|            Nintendo|   29.08|    3.58|    6.81|       0.77|       40.24|\n",
            "|   3|      Mario Kart Wii|     Wii|2008|      Racing|            Nintendo|   15.85|   12.88|    3.79|       3.31|       35.82|\n",
            "|   4|   Wii Sports Resort|     Wii|2009|      Sports|            Nintendo|   15.75|   11.01|    3.28|       2.96|        33.0|\n",
            "|   5|Pokemon Red/Pokem...|      GB|1996|Role-Playing|            Nintendo|   11.27|    8.89|   10.22|        1.0|       31.37|\n",
            "|   6|              Tetris|      GB|1989|      Puzzle|            Nintendo|    23.2|    2.26|    4.22|       0.58|       30.26|\n",
            "|   7|New Super Mario B...|      DS|2006|    Platform|            Nintendo|   11.38|    9.23|     6.5|        2.9|       30.01|\n",
            "|   8|            Wii Play|     Wii|2006|        Misc|            Nintendo|   14.03|     9.2|    2.93|       2.85|       29.02|\n",
            "|   9|New Super Mario B...|     Wii|2009|    Platform|            Nintendo|   14.59|    7.06|     4.7|       2.26|       28.62|\n",
            "|  10|           Duck Hunt|     NES|1984|     Shooter|            Nintendo|   26.93|    0.63|    0.28|       0.47|       28.31|\n",
            "|  11|          Nintendogs|      DS|2005|  Simulation|            Nintendo|    9.07|    11.0|    1.93|       2.75|       24.76|\n",
            "|  12|       Mario Kart DS|      DS|2005|      Racing|            Nintendo|    9.81|    7.57|    4.13|       1.92|       23.42|\n",
            "|  13|Pokemon Gold/Poke...|      GB|1999|Role-Playing|            Nintendo|     9.0|    6.18|     7.2|       0.71|        23.1|\n",
            "|  14|             Wii Fit|     Wii|2007|      Sports|            Nintendo|    8.94|    8.03|     3.6|       2.15|       22.72|\n",
            "|  15|        Wii Fit Plus|     Wii|2009|      Sports|            Nintendo|    9.09|    8.59|    2.53|       1.79|        22.0|\n",
            "|  16|  Kinect Adventures!|    X360|2010|        Misc|Microsoft Game St...|   14.97|    4.94|    0.24|       1.67|       21.82|\n",
            "|  17|  Grand Theft Auto V|     PS3|2013|      Action|Take-Two Interactive|    7.01|    9.27|    0.97|       4.14|        21.4|\n",
            "|  18|Grand Theft Auto:...|     PS2|2004|      Action|Take-Two Interactive|    9.43|     0.4|    0.41|      10.57|       20.81|\n",
            "|  19|   Super Mario World|    SNES|1990|    Platform|            Nintendo|   12.78|    3.75|    3.54|       0.55|       20.61|\n",
            "|  20|Brain Age: Train ...|      DS|2005|        Misc|            Nintendo|    4.75|    9.26|    4.16|       2.05|       20.22|\n",
            "+----+--------------------+--------+----+------------+--------------------+--------+--------+--------+-----------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "groupDF = spark.sql(\"SELECT Platform, count(*) from Year group by Platform\")\n",
        "groupDF.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcjaU212yz_a",
        "outputId": "f5724bfe-49c5-47f7-fc89-90a5a12a40c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+\n",
            "|Platform|count(1)|\n",
            "+--------+--------+\n",
            "|     3DO|       3|\n",
            "|      PC|     960|\n",
            "|     PS3|    1329|\n",
            "|     NES|      98|\n",
            "|      PS|    1196|\n",
            "|      DC|      52|\n",
            "|     GEN|      27|\n",
            "|     PS2|    2161|\n",
            "|     3DS|     509|\n",
            "|    PCFX|       1|\n",
            "|      GG|       1|\n",
            "|    WiiU|     143|\n",
            "|    SNES|     239|\n",
            "|      GB|      98|\n",
            "|     SCD|       6|\n",
            "|     N64|     319|\n",
            "|     PS4|     336|\n",
            "|     PSP|    1213|\n",
            "|    2600|     133|\n",
            "|    XOne|     213|\n",
            "+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Analysis"
      ],
      "metadata": {
        "id": "sZUn71C-06LM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Genre Analysis"
      ],
      "metadata": {
        "id": "2m7yZ0NGzr8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "genre_counts = df.groupBy(\"Genre\").count().orderBy(col(\"count\").desc())\n",
        "genre_counts.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AS6zW39eztuJ",
        "outputId": "c33470fb-52b8-4555-92fe-d4bc23e34ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|       Genre|count|\n",
            "+------------+-----+\n",
            "|      Action| 3316|\n",
            "|      Sports| 2346|\n",
            "|        Misc| 1739|\n",
            "|Role-Playing| 1488|\n",
            "|     Shooter| 1310|\n",
            "|   Adventure| 1286|\n",
            "|      Racing| 1249|\n",
            "|    Platform|  886|\n",
            "|  Simulation|  867|\n",
            "|    Fighting|  848|\n",
            "|    Strategy|  681|\n",
            "|      Puzzle|  582|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To find out which game genres have been made the most, you can count the number of occurrences of each genre."
      ],
      "metadata": {
        "id": "TD5YORft0EaY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Release Year Analysis"
      ],
      "metadata": {
        "id": "v3MiPcDjzuA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "release_counts = df.groupBy(\"Year\").count().orderBy(col(\"count\").desc())\n",
        "release_counts.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyweP1cPzuHp",
        "outputId": "9aeaaedb-7c6f-40e9-c2b8-66122a3c23bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|Year|count|\n",
            "+----+-----+\n",
            "|2009| 1431|\n",
            "|2008| 1428|\n",
            "|2010| 1259|\n",
            "|2007| 1202|\n",
            "|2011| 1139|\n",
            "|2006| 1008|\n",
            "|2005|  941|\n",
            "|2002|  829|\n",
            "|2003|  775|\n",
            "|2004|  763|\n",
            "|2012|  657|\n",
            "|2015|  614|\n",
            "|2014|  582|\n",
            "|2013|  546|\n",
            "|2001|  482|\n",
            "|1998|  379|\n",
            "|2000|  349|\n",
            "|2016|  344|\n",
            "|1999|  338|\n",
            "|1997|  289|\n",
            "+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Yearly Genre Release Analysis"
      ],
      "metadata": {
        "id": "HHBK-xMw0S5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "year_genre_counts = df.groupBy(\"Year\", \"Genre\").count().orderBy(col(\"count\").desc())\n",
        "year_genre_counts.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skh2Z1H10TDC",
        "outputId": "10cb05cc-0526-4626-c1e4-5b652e796e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------+-----+\n",
            "|Year|    Genre|count|\n",
            "+----+---------+-----+\n",
            "|2009|   Action|  272|\n",
            "|2012|   Action|  266|\n",
            "|2015|   Action|  255|\n",
            "|2011|   Action|  239|\n",
            "|2010|   Action|  226|\n",
            "|2008|   Action|  221|\n",
            "|2008|     Misc|  212|\n",
            "|2007|   Action|  211|\n",
            "|2009|     Misc|  207|\n",
            "|2010|     Misc|  201|\n",
            "|2008|   Sports|  200|\n",
            "|2005|   Action|  192|\n",
            "|2002|   Sports|  188|\n",
            "|2010|   Sports|  186|\n",
            "|2014|   Action|  186|\n",
            "|2006|   Action|  184|\n",
            "|2011|     Misc|  184|\n",
            "|2009|   Sports|  184|\n",
            "|2007|   Sports|  167|\n",
            "|2008|Adventure|  166|\n",
            "+----+---------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Regional Revenue Analysis"
      ],
      "metadata": {
        "id": "TD-auwWP0eVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum\n",
        "\n",
        "\n",
        "# Aggregate sales data by region\n",
        "region_sales = df.select(\n",
        "    _sum(\"NA_Sales\").alias(\"NA_Sales\"),\n",
        "    _sum(\"EU_Sales\").alias(\"EU_Sales\"),\n",
        "    _sum(\"JP_Sales\").alias(\"JP_Sales\"),\n",
        "    _sum(\"Other_Sales\").alias(\"Other_Sales\")\n",
        ")\n",
        "\n",
        "# Display the aggregated sales data\n",
        "region_sales.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM-ywFkX0dWZ",
        "outputId": "ea33e83d-0df9-4987-f36c-20d3f95be050"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+--------+-----------+\n",
            "|NA_Sales|EU_Sales|JP_Sales|Other_Sales|\n",
            "+--------+--------+--------+-----------+\n",
            "|    1763|     837|     406|        122|\n",
            "+--------+--------+--------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Distribution of Quantitative Variables"
      ],
      "metadata": {
        "id": "hUWF2E5a4toe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show basic statistics for the 'Global_Sales' column\n",
        "df.select(\"Global_Sales\").summary().show()\n",
        "\n",
        "# For more detailed analysis, use the agg() method\n",
        "from pyspark.sql.functions import mean, stddev, max, min\n",
        "\n",
        "df.agg(mean(\"Global_Sales\").alias(\"Mean\"),\n",
        "                        stddev(\"Global_Sales\").alias(\"StdDev\"),\n",
        "                        max(\"Global_Sales\").alias(\"Max\"),\n",
        "                        min(\"Global_Sales\").alias(\"Min\")).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30Z2ww3p4tt-",
        "outputId": "48a7febd-c1da-46c6-8a59-35329d106711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|summary|      Global_Sales|\n",
            "+-------+------------------+\n",
            "|  count|             16598|\n",
            "|   mean|0.2940113266658634|\n",
            "| stddev| 1.502527940050593|\n",
            "|    min|                 0|\n",
            "|    25%|                 0|\n",
            "|    50%|                 0|\n",
            "|    75%|                 0|\n",
            "|    max|                82|\n",
            "+-------+------------------+\n",
            "\n",
            "+------------------+-----------------+---+---+\n",
            "|              Mean|           StdDev|Max|Min|\n",
            "+------------------+-----------------+---+---+\n",
            "|0.2940113266658634|1.502527940050593| 82|  0|\n",
            "+------------------+-----------------+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Frequent in the database"
      ],
      "metadata": {
        "id": "s2DPqLxE-IpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 5 most frequent games in the database"
      ],
      "metadata": {
        "id": "LzH1docZ-W_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "# Group by the game name, count the occurrences, and order by count descending\n",
        "most_frequent_games = df.groupBy(\"Name\").count().orderBy(desc(\"count\"))\n",
        "\n",
        "# Show the top 5 most frequent games\n",
        "most_frequent_games.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OaVH1xy-Iu5",
        "outputId": "156d07f3-5749-457c-c978-d566454208ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+\n",
            "|                Name|count|\n",
            "+--------------------+-----+\n",
            "|Need for Speed: M...|   12|\n",
            "|LEGO Marvel Super...|    9|\n",
            "|       Madden NFL 07|    9|\n",
            "|         Ratatouille|    9|\n",
            "|             FIFA 14|    9|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 5 most frequent gaming platforms in the database¶"
      ],
      "metadata": {
        "id": "8N3EHYPH-VB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "# Group by the game name, count the occurrences, and order by count descending\n",
        "most_frequent_games = df.groupBy(\"Platform\").count().orderBy(desc(\"count\"))\n",
        "\n",
        "# Show the top 5 most frequent games\n",
        "most_frequent_games.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7j0I3act-b39",
        "outputId": "69c1c6fe-6f52-4b34-8b82-f962dc4173a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|Platform|count|\n",
            "+--------+-----+\n",
            "|      DS| 2163|\n",
            "|     PS2| 2161|\n",
            "|     PS3| 1329|\n",
            "|     Wii| 1325|\n",
            "|    X360| 1265|\n",
            "+--------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most Frequent Genre\n"
      ],
      "metadata": {
        "id": "BmlXiT17-zUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, lit, format_number\n",
        "\n",
        "# Group by 'Genre' and count the occurrences\n",
        "genre_counts = df.groupBy(\"Genre\").count().withColumnRenamed(\"count\", \"Frequency\")\n",
        "\n",
        "# Calculate the total number of games\n",
        "total_games = df.count()\n",
        "\n",
        "# Calculate the percentage of each genre\n",
        "genre_percentages = genre_counts.withColumn(\"Percent\", (col(\"Frequency\") / lit(total_games) * 100))\n",
        "\n",
        "# Format the percentage column for readability\n",
        "genre_percentages = genre_percentages.withColumn(\"Percent\", format_number(\"Percent\", 2))\n",
        "\n",
        "# Order by frequency descending to show the most common genres first\n",
        "genre_percentages_ordered = genre_percentages.orderBy(desc(\"Frequency\"))\n",
        "\n",
        "# Show the result\n",
        "genre_percentages_ordered.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmG-4Rv9-za5",
        "outputId": "f06c17f7-b348-4daa-d4d8-5e0f02087112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------+-------+\n",
            "|       Genre|Frequency|Percent|\n",
            "+------------+---------+-------+\n",
            "|      Action|     3316|  19.98|\n",
            "|      Sports|     2346|  14.13|\n",
            "|        Misc|     1739|  10.48|\n",
            "|Role-Playing|     1488|   8.96|\n",
            "|     Shooter|     1310|   7.89|\n",
            "|   Adventure|     1286|   7.75|\n",
            "|      Racing|     1249|   7.53|\n",
            "|    Platform|      886|   5.34|\n",
            "|  Simulation|      867|   5.22|\n",
            "|    Fighting|      848|   5.11|\n",
            "|    Strategy|      681|   4.10|\n",
            "|      Puzzle|      582|   3.51|\n",
            "+------------+---------+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 10 most frequent Publisher in the database"
      ],
      "metadata": {
        "id": "Qf9-3tA2_Hga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, lit, format_number\n",
        "\n",
        "# Group by 'Publisher' and count the occurrences\n",
        "Publisher_counts = df.groupBy(\"Publisher\").count().withColumnRenamed(\"count\", \"Frequency\")\n",
        "\n",
        "# Calculate the total number of games\n",
        "total_games = df.count()\n",
        "\n",
        "# Calculate the percentage of each Publisher\n",
        "Publisherpercentages = Publisher_counts.withColumn(\"Percent\", (col(\"Frequency\") / lit(total_games) * 100))\n",
        "\n",
        "# Format the percentage column for readability\n",
        "Publisherpercentages = Publisherpercentages.withColumn(\"Percent\", format_number(\"Percent\", 2))\n",
        "\n",
        "# Order by frequency descending to show the most common Publisher first\n",
        "Publisherpercentages_ordered = Publisherpercentages.orderBy(desc(\"Frequency\"))\n",
        "\n",
        "# Show the result\n",
        "Publisherpercentages_ordered.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uovCnwO_K9r",
        "outputId": "acd14bf5-ad2f-4e1c-a8c4-197eb1df46e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+-------+\n",
            "|           Publisher|Frequency|Percent|\n",
            "+--------------------+---------+-------+\n",
            "|     Electronic Arts|     1351|   8.14|\n",
            "|          Activision|      975|   5.87|\n",
            "|  Namco Bandai Games|      932|   5.62|\n",
            "|             Ubisoft|      921|   5.55|\n",
            "|Konami Digital En...|      832|   5.01|\n",
            "|                 THQ|      715|   4.31|\n",
            "|            Nintendo|      703|   4.24|\n",
            "|Sony Computer Ent...|      683|   4.11|\n",
            "|                Sega|      639|   3.85|\n",
            "|Take-Two Interactive|      413|   2.49|\n",
            "|              Capcom|      381|   2.30|\n",
            "|               Atari|      363|   2.19|\n",
            "|          Tecmo Koei|      338|   2.04|\n",
            "|         Square Enix|      233|   1.40|\n",
            "|Warner Bros. Inte...|      232|   1.40|\n",
            "|Disney Interactiv...|      218|   1.31|\n",
            "|             Unknown|      203|   1.22|\n",
            "|   Eidos Interactive|      198|   1.19|\n",
            "|        Midway Games|      198|   1.19|\n",
            "|           505 Games|      192|   1.16|\n",
            "+--------------------+---------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Anomaly Detection"
      ],
      "metadata": {
        "id": "hNmhJ_QpsvP5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import avg\n",
        "\n",
        "# Calculate the average sales for each genre\n",
        "avg_sales_by_genre = df.groupBy(\"Genre\").agg(avg(\"Global_Sales\").alias(\"Avg_Global_Sales\"))\n",
        "\n",
        "# Join back to the original dataframe\n",
        "df = df.join(avg_sales_by_genre, \"Genre\")\n"
      ],
      "metadata": {
        "id": "54quu1VEsvVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define high and low sales thresholds (e.g., more than double or less than half the average sales for its genre)\n",
        "df = df.withColumn(\"Sales_Anomaly\", when((col(\"Global_Sales\") > 2 * col(\"Avg_Global_Sales\")) | (col(\"Global_Sales\") < 0.5 * col(\"Avg_Global_Sales\")), 1).otherwise(0))\n",
        "\n",
        "# Filter to see anomalies\n",
        "df.filter(\"Sales_Anomaly = 1\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf6b0fz6szkH",
        "outputId": "a7e96791-0876-4d53-ee6e-6fedfac44492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----+--------------------+--------+----+--------------------+--------+--------+--------+-----------+------------+-----+-------------------+-------------+\n",
            "|       Genre|Rank|                Name|Platform|Year|           Publisher|NA_Sales|EU_Sales|JP_Sales|Other_Sales|Global_Sales|label|   Avg_Global_Sales|Sales_Anomaly|\n",
            "+------------+----+--------------------+--------+----+--------------------+--------+--------+--------+-----------+------------+-----+-------------------+-------------+\n",
            "|      Sports|   1|          Wii Sports|     Wii|2006|            Nintendo|      41|      29|       3|          8|          82|    1|0.28601875532821824|            1|\n",
            "|    Platform|   2|   Super Mario Bros.|     NES|1985|            Nintendo|      29|       3|       6|          0|          40|    1| 0.6489841986455982|            1|\n",
            "|      Racing|   3|      Mario Kart Wii|     Wii|2008|            Nintendo|      15|      12|       3|          3|          35|    1|0.33306645316253003|            1|\n",
            "|      Sports|   4|   Wii Sports Resort|     Wii|2009|            Nintendo|      15|      11|       3|          2|          33|    1|0.28601875532821824|            1|\n",
            "|Role-Playing|   5|Pokemon Red/Pokem...|      GB|1996|            Nintendo|      11|       8|      10|          1|          31|    1|0.37298387096774194|            1|\n",
            "|      Puzzle|   6|              Tetris|      GB|1989|            Nintendo|      23|       2|       4|          0|          30|    1|0.23367697594501718|            1|\n",
            "|    Platform|   7|New Super Mario B...|      DS|2006|            Nintendo|      11|       9|       6|          2|          30|    1| 0.6489841986455982|            1|\n",
            "|        Misc|   8|            Wii Play|     Wii|2006|            Nintendo|      14|       9|       2|          2|          29|    1|0.23634272570442783|            1|\n",
            "|    Platform|   9|New Super Mario B...|     Wii|2009|            Nintendo|      14|       7|       4|          2|          28|    1| 0.6489841986455982|            1|\n",
            "|     Shooter|  10|           Duck Hunt|     NES|1984|            Nintendo|      26|       0|       0|          0|          28|    1| 0.5076335877862596|            1|\n",
            "|  Simulation|  11|          Nintendogs|      DS|2005|            Nintendo|       9|      11|       1|          2|          24|    1|0.21914648212226068|            1|\n",
            "|      Racing|  12|       Mario Kart DS|      DS|2005|            Nintendo|       9|       7|       4|          1|          23|    1|0.33306645316253003|            1|\n",
            "|Role-Playing|  13|Pokemon Gold/Poke...|      GB|1999|            Nintendo|       9|       6|       7|          0|          23|    1|0.37298387096774194|            1|\n",
            "|      Sports|  14|             Wii Fit|     Wii|2007|            Nintendo|       8|       8|       3|          2|          22|    1|0.28601875532821824|            1|\n",
            "|      Sports|  15|        Wii Fit Plus|     Wii|2009|            Nintendo|       9|       8|       2|          1|          22|    1|0.28601875532821824|            1|\n",
            "|        Misc|  16|  Kinect Adventures!|    X360|2010|Microsoft Game St...|      14|       4|       0|          1|          21|    1|0.23634272570442783|            1|\n",
            "|      Action|  17|  Grand Theft Auto V|     PS3|2013|Take-Two Interactive|       7|       9|       0|          4|          21|    1|0.27291917973462004|            1|\n",
            "|      Action|  18|Grand Theft Auto:...|     PS2|2004|Take-Two Interactive|       9|       0|       0|         10|          20|    1|0.27291917973462004|            1|\n",
            "|    Platform|  19|   Super Mario World|    SNES|1990|            Nintendo|      12|       3|       3|          0|          20|    1| 0.6489841986455982|            1|\n",
            "|        Misc|  20|Brain Age: Train ...|      DS|2005|            Nintendo|       4|       9|       4|          2|          20|    1|0.23634272570442783|            1|\n",
            "+------------+----+--------------------+--------+----+--------------------+--------+--------+--------+-----------+------------+-----+-------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Relations of columns heatmap"
      ],
      "metadata": {
        "id": "yx4O72JAj3sW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import corr\n",
        "\n",
        "# Compute and show the correlation between NA_Sales and EU_Sales\n",
        "na_eu_corr = df.select(corr(\"NA_Sales\", \"EU_Sales\").alias(\"NA_EU_Correlation\"))\n",
        "na_eu_corr.show()\n",
        "\n",
        "# Compute and show the correlation between NA_Sales and Global_Sales\n",
        "na_global_corr = df.select(corr(\"NA_Sales\", \"Global_Sales\").alias(\"NA_Global_Correlation\"))\n",
        "na_global_corr.show()\n",
        "\n",
        "pandas_df = df.select(\"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"Global_Sales\").toPandas()\n",
        "corr_matrix = pandas_df.corr()\n",
        "print(corr_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzVY1cM2j377",
        "outputId": "48b83809-bc25-44b1-9daa-f1c898d0b22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+\n",
            "| NA_EU_Correlation|\n",
            "+------------------+\n",
            "|0.7282287675047117|\n",
            "+------------------+\n",
            "\n",
            "+---------------------+\n",
            "|NA_Global_Correlation|\n",
            "+---------------------+\n",
            "|   0.9221426317351326|\n",
            "+---------------------+\n",
            "\n",
            "              NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales\n",
            "NA_Sales      1.000000  0.728229  0.458591     0.481687      0.922143\n",
            "EU_Sales      0.728229  1.000000  0.434468     0.578514      0.865857\n",
            "JP_Sales      0.458591  0.434468  1.000000     0.188363      0.594700\n",
            "Other_Sales   0.481687  0.578514  0.188363     1.000000      0.572492\n",
            "Global_Sales  0.922143  0.865857  0.594700     0.572492      1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. SALES"
      ],
      "metadata": {
        "id": "7Z6QDMlPiQ2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Best selling"
      ],
      "metadata": {
        "id": "gEWQrpx3hDvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of the world's best-selling games"
      ],
      "metadata": {
        "id": "6bOYqJNTg2YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "# Aggregate and sort NA_Sales\n",
        "best_selling_na = df.groupBy(\"Name\").agg(sum(\"NA_Sales\").alias(\"Total_NA_Sales\")).orderBy(desc(\"Total_NA_Sales\"))\n",
        "\n",
        "# Aggregate and sort EU_Sales\n",
        "best_selling_eu = df.groupBy(\"Name\").agg(sum(\"EU_Sales\").alias(\"Total_EU_Sales\")).orderBy(desc(\"Total_EU_Sales\"))\n",
        "\n",
        "# Aggregate and sort JP_Sales\n",
        "best_selling_jp = df.groupBy(\"Name\").agg(sum(\"JP_Sales\").alias(\"Total_JP_Sales\")).orderBy(desc(\"Total_JP_Sales\"))\n",
        "\n",
        "# Aggregate and sort Other_Sales\n",
        "best_selling_other = df.groupBy(\"Name\").agg(sum(\"Other_Sales\").alias(\"Total_Other_Sales\")).orderBy(desc(\"Total_Other_Sales\"))\n",
        "\n",
        "# Aggregate and sort Global_Sales\n",
        "best_selling_global = df.groupBy(\"Name\").agg(sum(\"Global_Sales\").alias(\"Total_Global_Sales\")).orderBy(desc(\"Total_Global_Sales\"))\n",
        "\n",
        "# Show the top games for each region and globally\n",
        "print(\"Best Selling Games in North America:\")\n",
        "best_selling_na.show(5)\n",
        "print(\"Best Selling Games in Europe:\")\n",
        "best_selling_eu.show(5)\n",
        "print(\"Best Selling Games in Japan:\")\n",
        "best_selling_jp.show(5)\n",
        "print(\"Best Selling Games in Other Regions:\")\n",
        "best_selling_other.show(5)\n",
        "print(\"Best Selling Games Globally:\")\n",
        "best_selling_global.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2w4Kd-wg3Lo",
        "outputId": "86415e1a-c5cd-4a19-90cf-cda8f24c52f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Selling Games in North America:\n",
            "+------------------+--------------+\n",
            "|              Name|Total_NA_Sales|\n",
            "+------------------+--------------+\n",
            "|        Wii Sports|            41|\n",
            "| Super Mario Bros.|            32|\n",
            "|         Duck Hunt|            26|\n",
            "|            Tetris|            25|\n",
            "|Grand Theft Auto V|            21|\n",
            "+------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Best Selling Games in Europe:\n",
            "+------------------+--------------+\n",
            "|              Name|Total_EU_Sales|\n",
            "+------------------+--------------+\n",
            "|        Wii Sports|            29|\n",
            "|Grand Theft Auto V|            21|\n",
            "|    Mario Kart Wii|            12|\n",
            "|        Nintendogs|            11|\n",
            "| Wii Sports Resort|            11|\n",
            "+------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Best Selling Games in Japan:\n",
            "+--------------------+--------------+\n",
            "|                Name|Total_JP_Sales|\n",
            "+--------------------+--------------+\n",
            "|Pokemon Red/Pokem...|            10|\n",
            "|Pokemon Gold/Poke...|             7|\n",
            "|Pokemon Diamond/P...|             6|\n",
            "|New Super Mario B...|             6|\n",
            "|   Super Mario Bros.|             6|\n",
            "+--------------------+--------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Best Selling Games in Other Regions:\n",
            "+--------------------+-----------------+\n",
            "|                Name|Total_Other_Sales|\n",
            "+--------------------+-----------------+\n",
            "|Grand Theft Auto:...|               10|\n",
            "|          Wii Sports|                8|\n",
            "|  Grand Theft Auto V|                7|\n",
            "|      Gran Turismo 4|                7|\n",
            "|Call of Duty: Bla...|                3|\n",
            "+--------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Best Selling Games Globally:\n",
            "+------------------+------------------+\n",
            "|              Name|Total_Global_Sales|\n",
            "+------------------+------------------+\n",
            "|        Wii Sports|                82|\n",
            "|Grand Theft Auto V|                54|\n",
            "| Super Mario Bros.|                45|\n",
            "|    Mario Kart Wii|                35|\n",
            "|            Tetris|                35|\n",
            "+------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "best-selling games globally from 1980 to 2016"
      ],
      "metadata": {
        "id": "bxp2GTkkhJT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col, desc\n",
        "\n",
        "# Filter the DataFrame for the years 1980 to 2016\n",
        "filtered_df = df.filter((col(\"Year\") >= 1980) & (col(\"Year\") <= 2016))\n",
        "\n",
        "# Aggregate global sales by game name and sort in descending order\n",
        "best_selling_games_global = filtered_df.groupBy(\"Name\").agg(_sum(\"Global_Sales\").alias(\"Total_Global_Sales\")).orderBy(desc(\"Total_Global_Sales\"))\n",
        "\n",
        "# Show the top best-selling games globally from 1980 to 2016\n",
        "best_selling_games_global.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIHQoayAhJb0",
        "outputId": "1c39a4b4-26b9-4e3d-9107-ebc1beb0c510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|                Name|Total_Global_Sales|\n",
            "+--------------------+------------------+\n",
            "|          Wii Sports|                82|\n",
            "|  Grand Theft Auto V|                54|\n",
            "|   Super Mario Bros.|                45|\n",
            "|      Mario Kart Wii|                35|\n",
            "|              Tetris|                35|\n",
            "|   Wii Sports Resort|                33|\n",
            "|Pokemon Red/Pokem...|                31|\n",
            "|New Super Mario B...|                30|\n",
            "|            Wii Play|                29|\n",
            "|           Duck Hunt|                28|\n",
            "+--------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col, desc\n",
        "\n",
        "# Filter the DataFrame for the 2016\n",
        "filtered_df = df.filter((col(\"Year\") >= 2016) & (col(\"Year\") <= 2016))\n",
        "\n",
        "# Aggregate global sales by game name and sort in descending order\n",
        "best_selling_games_global = filtered_df.groupBy(\"Name\").agg(_sum(\"Global_Sales\").alias(\"Total_Global_Sales\")).orderBy(desc(\"Total_Global_Sales\"))\n",
        "\n",
        "# Show the top best-selling games globally from\n",
        "best_selling_games_global.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmLm4OpGhPmJ",
        "outputId": "9c4b559f-9b36-4ff7-d379-aa2f046b7423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|                Name|Total_Global_Sales|\n",
            "+--------------------+------------------+\n",
            "|Tom Clancy's The ...|                 5|\n",
            "|             FIFA 17|                 5|\n",
            "|Uncharted 4: A Th...|                 4|\n",
            "|     Far Cry: Primal|                 2|\n",
            "|Ratchet & Clank (...|                 1|\n",
            "|         Doom (2016)|                 1|\n",
            "|       Madden NFL 17|                 1|\n",
            "|            NBA 2K17|                 1|\n",
            "|Naruto Shippuden:...|                 1|\n",
            "|           Overwatch|                 1|\n",
            "+--------------------+------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Number of Sales per platform"
      ],
      "metadata": {
        "id": "rM6zLC6Ohniv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col, desc\n",
        "\n",
        "# Aggregate and sort NA_Sales per platform\n",
        "total_sales_na = df.groupBy(\"Platform\").agg(_sum(\"NA_Sales\").alias(\"Total_NA_Sales\")).orderBy(desc(\"Total_NA_Sales\"))\n",
        "\n",
        "# Aggregate and sort EU_Sales per platform\n",
        "total_sales_eu = df.groupBy(\"Platform\").agg(_sum(\"EU_Sales\").alias(\"Total_EU_Sales\")).orderBy(desc(\"Total_EU_Sales\"))\n",
        "\n",
        "# Aggregate and sort JP_Sales per platform\n",
        "total_sales_jp = df.groupBy(\"Platform\").agg(_sum(\"JP_Sales\").alias(\"Total_JP_Sales\")).orderBy(desc(\"Total_JP_Sales\"))\n",
        "\n",
        "# Aggregate and sort Other_Sales per platform\n",
        "total_sales_other = df.groupBy(\"Platform\").agg(_sum(\"Other_Sales\").alias(\"Total_Other_Sales\")).orderBy(desc(\"Total_Other_Sales\"))\n",
        "\n",
        "# Aggregate and sort Global_Sales per platform\n",
        "total_sales_global = df.groupBy(\"Platform\").agg(_sum(\"Global_Sales\").alias(\"Total_Global_Sales\")).orderBy(desc(\"Total_Global_Sales\"))\n",
        "\n",
        "# Display the results\n",
        "print(\"Total NA Sales per Platform:\")\n",
        "total_sales_na.show()\n",
        "print(\"Total EU Sales per Platform:\")\n",
        "total_sales_eu.show()\n",
        "print(\"Total JP Sales per Platform:\")\n",
        "total_sales_jp.show()\n",
        "print(\"Total Other Sales per Platform:\")\n",
        "total_sales_other.show()\n",
        "print(\"Total Global Sales per Platform:\")\n",
        "total_sales_global.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfxcmH9zhvfk",
        "outputId": "d57a2cd4-5a3f-4a43-f34d-306238d840ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total NA Sales per Platform:\n",
            "+--------+--------------+\n",
            "|Platform|Total_NA_Sales|\n",
            "+--------+--------------+\n",
            "|    X360|           288|\n",
            "|     Wii|           237|\n",
            "|     PS2|           225|\n",
            "|     PS3|           135|\n",
            "|      PS|           132|\n",
            "|      DS|           113|\n",
            "|     NES|            94|\n",
            "|      GB|            89|\n",
            "|     N64|            61|\n",
            "|     GBA|            49|\n",
            "|      PC|            44|\n",
            "|    SNES|            43|\n",
            "|     PS4|            40|\n",
            "|    2600|            39|\n",
            "|    XOne|            35|\n",
            "|     3DS|            32|\n",
            "|      XB|            32|\n",
            "|      GC|            30|\n",
            "|     GEN|            14|\n",
            "|    WiiU|            14|\n",
            "+--------+--------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total EU Sales per Platform:\n",
            "+--------+--------------+\n",
            "|Platform|Total_EU_Sales|\n",
            "+--------+--------------+\n",
            "|     Wii|           137|\n",
            "|     PS3|           124|\n",
            "|     PS2|           108|\n",
            "|      DS|            87|\n",
            "|    X360|            86|\n",
            "|      PS|            65|\n",
            "|     PS4|            61|\n",
            "|      PC|            44|\n",
            "|      GB|            28|\n",
            "|     3DS|            24|\n",
            "|     PSP|            13|\n",
            "|    XOne|            12|\n",
            "|     GBA|            12|\n",
            "|     N64|             8|\n",
            "|     NES|             7|\n",
            "|    WiiU|             7|\n",
            "|    SNES|             7|\n",
            "|      GC|             3|\n",
            "|      XB|             3|\n",
            "|     GEN|             1|\n",
            "+--------+--------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total JP Sales per Platform:\n",
            "+--------+--------------+\n",
            "|Platform|Total_JP_Sales|\n",
            "+--------+--------------+\n",
            "|      DS|            76|\n",
            "|     NES|            57|\n",
            "|      GB|            51|\n",
            "|    SNES|            45|\n",
            "|      PS|            42|\n",
            "|     3DS|            41|\n",
            "|     Wii|            29|\n",
            "|     PS2|            25|\n",
            "|     N64|            12|\n",
            "|     GBA|            11|\n",
            "|     PSP|            10|\n",
            "|    WiiU|             3|\n",
            "|     PS3|             2|\n",
            "|      GC|             1|\n",
            "|     SAT|             1|\n",
            "|     3DO|             0|\n",
            "|      PC|             0|\n",
            "|      DC|             0|\n",
            "|     GEN|             0|\n",
            "|    PCFX|             0|\n",
            "+--------+--------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total Other Sales per Platform:\n",
            "+--------+-----------------+\n",
            "|Platform|Total_Other_Sales|\n",
            "+--------+-----------------+\n",
            "|     PS2|               42|\n",
            "|     PS3|               27|\n",
            "|     Wii|               22|\n",
            "|     PS4|                9|\n",
            "|      DS|                9|\n",
            "|    X360|                8|\n",
            "|     PSP|                2|\n",
            "|      PC|                1|\n",
            "|     NES|                1|\n",
            "|      GB|                1|\n",
            "|     3DO|                0|\n",
            "|      PS|                0|\n",
            "|      DC|                0|\n",
            "|     GEN|                0|\n",
            "|     3DS|                0|\n",
            "|    PCFX|                0|\n",
            "|      GG|                0|\n",
            "|    WiiU|                0|\n",
            "|    SNES|                0|\n",
            "|     SCD|                0|\n",
            "+--------+-----------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Total Global Sales per Platform:\n",
            "+--------+------------------+\n",
            "|Platform|Total_Global_Sales|\n",
            "+--------+------------------+\n",
            "|     PS2|               645|\n",
            "|    X360|               590|\n",
            "|     Wii|               574|\n",
            "|     PS3|               544|\n",
            "|      DS|               423|\n",
            "|      PS|               384|\n",
            "|      GB|               220|\n",
            "|     NES|               211|\n",
            "|     PS4|               184|\n",
            "|     3DS|               142|\n",
            "|     GBA|               132|\n",
            "|      PC|               126|\n",
            "|    SNES|               125|\n",
            "|     N64|               120|\n",
            "|     PSP|                97|\n",
            "|    XOne|                84|\n",
            "|      GC|                76|\n",
            "|      XB|                75|\n",
            "|    WiiU|                44|\n",
            "|    2600|                42|\n",
            "+--------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 10 platforms with the highest number of game sales in the world"
      ],
      "metadata": {
        "id": "AotcURxnh_Ac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col, desc\n",
        "\n",
        "# Aggregate global sales by platform\n",
        "platform_global_sales = df.groupBy(\"Platform\").agg(_sum(\"Global_Sales\").alias(\"Total_Global_Sales\"))\n",
        "\n",
        "# Order the results by Total_Global_Sales in descending order and take the top 10\n",
        "top_platforms_global_sales = platform_global_sales.orderBy(desc(\"Total_Global_Sales\")).limit(10)\n",
        "\n",
        "# Show the results\n",
        "top_platforms_global_sales.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLI9Srjhh_HJ",
        "outputId": "a686dc6e-ad50-4d36-dd21-6cd0b61a6422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+\n",
            "|Platform|Total_Global_Sales|\n",
            "+--------+------------------+\n",
            "|     PS2|               645|\n",
            "|    X360|               590|\n",
            "|     Wii|               574|\n",
            "|     PS3|               544|\n",
            "|      DS|               423|\n",
            "|      PS|               384|\n",
            "|      GB|               220|\n",
            "|     NES|               211|\n",
            "|     PS4|               184|\n",
            "|     3DS|               142|\n",
            "+--------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Game Sales by Genre"
      ],
      "metadata": {
        "id": "8nL8UGCLiI9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col, desc\n",
        "\n",
        "# Filter the DataFrame for the years 1980 to 2016\n",
        "filtered_df = df.filter((col(\"Year\") >= 1980) & (col(\"Year\") <= 2016))\n",
        "\n",
        "# Aggregate sales by genre\n",
        "genre_sales = filtered_df.groupBy(\"Genre\").agg(\n",
        "    _sum(\"Global_Sales\").alias(\"Total_Global_Sales\"),\n",
        "    _sum(\"NA_Sales\").alias(\"Total_NA_Sales\"),\n",
        "    _sum(\"EU_Sales\").alias(\"Total_EU_Sales\"),\n",
        "    _sum(\"JP_Sales\").alias(\"Total_JP_Sales\"),\n",
        "    _sum(\"Other_Sales\").alias(\"Total_Other_Sales\")\n",
        ")\n",
        "\n",
        "# Sort the results by total global sales in descending order\n",
        "sorted_genre_sales = genre_sales.orderBy(desc(\"Total_Global_Sales\"))\n",
        "\n",
        "# Show the best-selling genres from 1980 to 2016\n",
        "sorted_genre_sales.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHt80hMuiO4s",
        "outputId": "2b1b856d-bf4c-4c5c-f5ad-aa00c1ba4bad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+--------------+--------------+--------------+-----------------+\n",
            "|       Genre|Total_Global_Sales|Total_NA_Sales|Total_EU_Sales|Total_JP_Sales|Total_Other_Sales|\n",
            "+------------+------------------+--------------+--------------+--------------+-----------------+\n",
            "|      Action|               895|           294|           153|            24|               33|\n",
            "|      Sports|               662|           240|           151|            35|               28|\n",
            "|     Shooter|               660|           297|           117|             4|               17|\n",
            "|    Platform|               574|           251|            80|            64|                4|\n",
            "|Role-Playing|               555|           140|            81|           158|                7|\n",
            "|      Racing|               415|           140|            80|            22|               17|\n",
            "|        Misc|               405|           155|            74|            32|               10|\n",
            "|    Fighting|               222|            81|            21|            18|                3|\n",
            "|  Simulation|               190|            51|            41|            19|                2|\n",
            "|      Puzzle|               136|            55|            15|            21|                1|\n",
            "|   Adventure|                73|            22|            11|             4|                0|\n",
            "|    Strategy|                55|            21|             9|             5|                0|\n",
            "+------------+------------------+--------------+--------------+--------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which genre game has sold the most in a single year"
      ],
      "metadata": {
        "id": "2LYcPgXckkYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col, sum as _sum\n",
        "\n",
        "# Step 1: Aggregate sales by year and genre\n",
        "year_genre_sales = df.groupBy(\"Year\", \"Genre\").agg(_sum(\"Global_Sales\").alias(\"Total_Sales\"))\n",
        "\n",
        "# Step 2: Use a window function to rank genres within each year by Total_Sales\n",
        "windowSpec = Window.partitionBy(\"Year\").orderBy(col(\"Total_Sales\").desc())\n",
        "\n",
        "# Apply the window specification to add a rank column\n",
        "ranked_year_genre_sales = year_genre_sales.withColumn(\"Rank\", rank().over(windowSpec))\n",
        "\n",
        "# Filter to get only the top genre of each year (rank = 1)\n",
        "top_genre_per_year = ranked_year_genre_sales.filter(col(\"Rank\") == 1).orderBy(\"Year\")\n",
        "\n",
        "# Show the result\n",
        "top_genre_per_year.select(\"Year\", \"Genre\", \"Total_Sales\").show(39)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxRsOqPvkfcW",
        "outputId": "638b1088-1c03-4e14-b557-16b7ae917a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------+-----------+\n",
            "|Year|       Genre|Total_Sales|\n",
            "+----+------------+-----------+\n",
            "|NULL|      Action|         10|\n",
            "|1980|     Shooter|          6|\n",
            "|1981|     Shooter|          7|\n",
            "|1982|      Puzzle|          8|\n",
            "|1983|    Platform|          6|\n",
            "|1984|     Shooter|         30|\n",
            "|1985|    Platform|         41|\n",
            "|1986|      Action|         11|\n",
            "|1987|    Fighting|          5|\n",
            "|1988|    Platform|         26|\n",
            "|1989|      Puzzle|         36|\n",
            "|1990|    Platform|         22|\n",
            "|1991|    Platform|          5|\n",
            "|1991|      Action|          5|\n",
            "|1992|    Fighting|         13|\n",
            "|1993|    Platform|         14|\n",
            "|1994|    Platform|         24|\n",
            "|1995|    Platform|         14|\n",
            "|1996|Role-Playing|         36|\n",
            "|1997|      Racing|         20|\n",
            "|1998|      Action|         27|\n",
            "|1999|Role-Playing|         35|\n",
            "|2000|      Action|         20|\n",
            "|2001|      Action|         39|\n",
            "|2002|      Action|         54|\n",
            "|2003|      Action|         31|\n",
            "|2004|      Action|         43|\n",
            "|2005|  Simulation|         40|\n",
            "|2006|      Sports|        101|\n",
            "|2007|        Misc|         57|\n",
            "|2008|      Action|         78|\n",
            "|2009|      Sports|         87|\n",
            "|2010|      Action|         58|\n",
            "|2011|     Shooter|         68|\n",
            "|2012|      Action|         57|\n",
            "|2013|      Action|         83|\n",
            "|2014|      Action|         50|\n",
            "|2015|     Shooter|         53|\n",
            "|2016|     Shooter|         11|\n",
            "+----+------------+-----------+\n",
            "only showing top 39 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Number of sales per publisher\n",
        "\n"
      ],
      "metadata": {
        "id": "EAs_7hK_i2m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col, desc\n",
        "\n",
        "# Aggregate global sales by publisher\n",
        "publisher_sales = df.groupBy(\"Publisher\").agg(_sum(\"Global_Sales\").alias(\"Total_Global_Sales\"))\n",
        "\n",
        "# Order the results by Total_Global_Sales in descending order\n",
        "top_publishers_global_sales = publisher_sales.orderBy(desc(\"Total_Global_Sales\"))\n",
        "\n",
        "# Show the top publishers by total global sales\n",
        "top_publishers_global_sales.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-1tjUT6i5Ug",
        "outputId": "1c5ecce2-0bc3-48fa-f52e-a1beeec74923"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|           Publisher|Total_Global_Sales|\n",
            "+--------------------+------------------+\n",
            "|            Nintendo|              1510|\n",
            "|     Electronic Arts|               595|\n",
            "|          Activision|               421|\n",
            "|Sony Computer Ent...|               366|\n",
            "|Take-Two Interactive|               271|\n",
            "|             Ubisoft|               230|\n",
            "|Microsoft Game St...|               187|\n",
            "|                 THQ|               119|\n",
            "|                Sega|               114|\n",
            "|Konami Digital En...|               109|\n",
            "|              Capcom|               103|\n",
            "|  Namco Bandai Games|                74|\n",
            "|Warner Bros. Inte...|                69|\n",
            "|         Square Enix|                66|\n",
            "|               Atari|                64|\n",
            "|  Bethesda Softworks|                55|\n",
            "|   Eidos Interactive|                54|\n",
            "|           LucasArts|                52|\n",
            "|Disney Interactiv...|                43|\n",
            "|          SquareSoft|                36|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global Sales Number per Year"
      ],
      "metadata": {
        "id": "oGRYKknUjJP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col\n",
        "\n",
        "# Aggregate global sales by year\n",
        "yearly_global_sales = df.groupBy(\"Year\").agg(_sum(\"Global_Sales\").alias(\"Total_Global_Sales\"))\n",
        "\n",
        "# Order the results by Year\n",
        "sorted_yearly_global_sales = yearly_global_sales.orderBy(col(\"Year\"))\n",
        "\n",
        "# Show the global sales number per year\n",
        "sorted_yearly_global_sales.show(37)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMFpmxQDjLPz",
        "outputId": "d73d7ebd-3847-4dd0-9486-7eed5e74d62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------------+\n",
            "|Year|Total_Global_Sales|\n",
            "+----+------------------+\n",
            "|NULL|                38|\n",
            "|1980|                 8|\n",
            "|1981|                16|\n",
            "|1982|                13|\n",
            "|1983|                11|\n",
            "|1984|                45|\n",
            "|1985|                49|\n",
            "|1986|                28|\n",
            "|1987|                15|\n",
            "|1988|                41|\n",
            "|1989|                67|\n",
            "|1990|                43|\n",
            "|1991|                17|\n",
            "|1992|                62|\n",
            "|1993|                26|\n",
            "|1994|                44|\n",
            "|1995|                43|\n",
            "|1996|               126|\n",
            "|1997|               119|\n",
            "|1998|               151|\n",
            "|1999|               143|\n",
            "|2000|                99|\n",
            "|2001|               190|\n",
            "|2002|               196|\n",
            "|2003|               159|\n",
            "|2004|               207|\n",
            "|2005|               234|\n",
            "|2006|               323|\n",
            "|2007|               332|\n",
            "|2008|               334|\n",
            "|2009|               331|\n",
            "|2010|               320|\n",
            "|2011|               266|\n",
            "|2012|               198|\n",
            "|2013|               224|\n",
            "|2014|               193|\n",
            "|2015|               144|\n",
            "+----+------------------+\n",
            "only showing top 37 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Central Trend Measures"
      ],
      "metadata": {
        "id": "GJDk4CZk_vhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean"
      ],
      "metadata": {
        "id": "7ISst3-FADcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the percentiles you're interested in as a list of decimal values\n",
        "percentiles = [0.25, 0.5, 0.75, 0.99]\n",
        "\n",
        "# Calculate the approximate quantiles for each sales column\n",
        "na_sales_quantiles = df.approxQuantile(\"NA_Sales\", percentiles, 0.05)\n",
        "eu_sales_quantiles = df.approxQuantile(\"EU_Sales\", percentiles, 0.05)\n",
        "jp_sales_quantiles = df.approxQuantile(\"JP_Sales\", percentiles, 0.05)\n",
        "other_sales_quantiles = df.approxQuantile(\"Other_Sales\", percentiles, 0.05)\n",
        "global_sales_quantiles = df.approxQuantile(\"Global_Sales\", percentiles, 0.05)\n",
        "\n",
        "# Print the results\n",
        "print(\"Percentile\\tNA_Sales\\tEU_Sales\\tJP_Sales\\tOther_Sales\\tGlobal_Sales\")\n",
        "for i, pct in enumerate(percentiles):\n",
        "    print(f\"{pct*100}%\\t\\t{na_sales_quantiles[i]:.4f}\\t\\t{eu_sales_quantiles[i]:.4f}\\t\\t{jp_sales_quantiles[i]:.4f}\\t\\t{other_sales_quantiles[i]:.4f}\\t\\t{global_sales_quantiles[i]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "448doA7B_zCi",
        "outputId": "73cf71d9-0320-42a1-e913-172348ef9093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentile\tNA_Sales\tEU_Sales\tJP_Sales\tOther_Sales\tGlobal_Sales\n",
            "25.0%\t\t0.0000\t\t0.0000\t\t0.0000\t\t0.0000\t\t0.0000\n",
            "50.0%\t\t0.0000\t\t0.0000\t\t0.0000\t\t0.0000\t\t0.0000\n",
            "75.0%\t\t0.0000\t\t0.0000\t\t0.0000\t\t0.0000\t\t0.0000\n",
            "99.0%\t\t41.0000\t\t29.0000\t\t10.0000\t\t10.0000\t\t82.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "percentiles"
      ],
      "metadata": {
        "id": "fygYXFcnAI_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty dictionary to store the percentile results for each column\n",
        "percentile_results = {\"NA_Sales\": [], \"EU_Sales\": [], \"JP_Sales\": [], \"Other_Sales\": [], \"Global_Sales\": []}\n",
        "\n",
        "# Define the percentiles from 1% to 99%\n",
        "percentiles = [i / 100 for i in range(1, 100)]\n",
        "\n",
        "# Calculate approximate quantiles for each column\n",
        "for column in percentile_results.keys():\n",
        "    percentile_results[column] = df.approxQuantile(column, percentiles, 0.05)\n",
        "\n",
        "# Convert the dictionary to a DataFrame for display\n",
        "# This step is to format the output similar to the R example; however, PySpark doesn't have a direct equivalent of R's data.frame\n",
        "# We'll collect the results back to the driver to construct the final display DataFrame using pandas (note: be cautious with large datasets)\n",
        "import pandas as pd\n",
        "\n",
        "# Prepare data for pandas DataFrame\n",
        "data_for_df = []\n",
        "for i, pct in enumerate(percentiles):\n",
        "    row = [pct]\n",
        "    for column in percentile_results.keys():\n",
        "        row.append(percentile_results[column][i])\n",
        "    data_for_df.append(row)\n",
        "\n",
        "# Column names for the DataFrame\n",
        "columns = ['Percentile'] + list(percentile_results.keys())\n",
        "\n",
        "# Create pandas DataFrame\n",
        "percentile_df = pd.DataFrame(data_for_df, columns=columns)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(percentile_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZUh169hAJmV",
        "outputId": "cdb1844e-5afa-40ad-c136-e2d00692d535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Percentile  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales\n",
            "0         0.01       0.0       0.0       0.0          0.0           0.0\n",
            "1         0.02       0.0       0.0       0.0          0.0           0.0\n",
            "2         0.03       0.0       0.0       0.0          0.0           0.0\n",
            "3         0.04       0.0       0.0       0.0          0.0           0.0\n",
            "4         0.05       0.0       0.0       0.0          0.0           0.0\n",
            "..         ...       ...       ...       ...          ...           ...\n",
            "94        0.95      41.0      29.0      10.0         10.0          82.0\n",
            "95        0.96      41.0      29.0      10.0         10.0          82.0\n",
            "96        0.97      41.0      29.0      10.0         10.0          82.0\n",
            "97        0.98      41.0      29.0      10.0         10.0          82.0\n",
            "98        0.99      41.0      29.0      10.0         10.0          82.0\n",
            "\n",
            "[99 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "standard deviation"
      ],
      "metadata": {
        "id": "m07mmEM9ghSE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import stddev_pop\n",
        "\n",
        "# Calculate the population standard deviation for each sales column\n",
        "stddev_sales = df.agg(\n",
        "    stddev_pop(\"NA_Sales\").alias(\"NA_Sales\"),\n",
        "    stddev_pop(\"EU_Sales\").alias(\"EU_Sales\"),\n",
        "    stddev_pop(\"JP_Sales\").alias(\"JP_Sales\"),\n",
        "    stddev_pop(\"Other_Sales\").alias(\"Other_Sales\"),\n",
        "    stddev_pop(\"Global_Sales\").alias(\"Global_Sales\")\n",
        ")\n",
        "\n",
        "# Show the result\n",
        "stddev_sales.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdKJ0OO7gh5i",
        "outputId": "72382943-b2fe-4941-a952-0988b0e1fe0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------------+------------------+------------------+------------------+\n",
            "|         NA_Sales|          EU_Sales|          JP_Sales|       Other_Sales|      Global_Sales|\n",
            "+-----------------+------------------+------------------+------------------+------------------+\n",
            "|0.752140310387462|0.4464849773209801|0.2508052970368341|0.1466793682011568|1.5024826770498731|\n",
            "+-----------------+------------------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Time Series Analysis: Trend Analysis"
      ],
      "metadata": {
        "id": "rB9lYvPs8MV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum\n",
        "\n",
        "# Assuming your DataFrame is named df and \"Year\" column is already an integer\n",
        "yearly_sales = df.groupBy(\"Year\").agg(_sum(\"Global_Sales\").alias(\"Total_Sales\"))\n",
        "\n",
        "yearly_sales.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDicLSjO84B_",
        "outputId": "aea34cf6-c47c-4ff2-b102-43febf1afcad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+\n",
            "|Year|Total_Sales|\n",
            "+----+-----------+\n",
            "|1990|         43|\n",
            "|2003|        159|\n",
            "|2007|        332|\n",
            "|2015|        144|\n",
            "|2006|        323|\n",
            "|2013|        224|\n",
            "|NULL|         38|\n",
            "|1988|         41|\n",
            "|1997|        119|\n",
            "|1994|         44|\n",
            "|2014|        193|\n",
            "|2004|        207|\n",
            "|1991|         17|\n",
            "|1982|         13|\n",
            "|1996|        126|\n",
            "|1989|         67|\n",
            "|1998|        151|\n",
            "|1985|         49|\n",
            "|2020|          0|\n",
            "|2012|        198|\n",
            "+----+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum as _sum, col, isnan, when, count\n",
        "\n",
        "# Filter out rows with NULL or invalid Year values before aggregating\n",
        "yearly_sales_filtered = df.filter(df.Year.isNotNull()).groupBy(\"Year\").agg(_sum(\"Global_Sales\").alias(\"Total_Sales\"))\n",
        "\n",
        "# Recalculate the moving average on the filtered DataFrame\n",
        "moving_avg_filtered = yearly_sales_filtered.withColumn(\"Moving_Avg\", avg(\"Total_Sales\").over(windowSpec))\n",
        "moving_avg_filtered.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gfJ6Es-9IYq",
        "outputId": "8dee9924-b7d9-4c88-cfe7-b0ce9d2ad3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+------------------+\n",
            "|Year|Total_Sales|        Moving_Avg|\n",
            "+----+-----------+------------------+\n",
            "|1980|          8|12.333333333333334|\n",
            "|1981|         16|              12.0|\n",
            "|1982|         13|              18.6|\n",
            "|1983|         11|              26.8|\n",
            "|1984|         45|              29.2|\n",
            "|1985|         49|              29.6|\n",
            "|1986|         28|              35.6|\n",
            "|1987|         15|              40.0|\n",
            "|1988|         41|              38.8|\n",
            "|1989|         67|              36.6|\n",
            "|1990|         43|              46.0|\n",
            "|1991|         17|              43.0|\n",
            "|1992|         62|              38.4|\n",
            "|1993|         26|              38.4|\n",
            "|1994|         44|              60.2|\n",
            "|1995|         43|              71.6|\n",
            "|1996|        126|              96.6|\n",
            "|1997|        119|             116.4|\n",
            "|1998|        151|             127.6|\n",
            "|1999|        143|             140.4|\n",
            "+----+-----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Growth Periods: Years where the moving average significantly increases from one year to the next indicate periods of rapid growth in the industry. For instance, the jump from 1994 to 1996 suggests a significant increase in video game sales, likely due to technological advancements, popular game releases, or expansion of the gaming market.\n",
        "Stabilization and Declines: Periods where the moving average remains relatively stable or decreases could indicate market saturation, the impact of external factors, or shifts in consumer behavior."
      ],
      "metadata": {
        "id": "Y7NFKKtJ9Vk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, col\n",
        "\n",
        "# Group by Year and Platform, then calculate total sales\n",
        "platform_yearly_sales = df.groupBy(\"Year\", \"Platform\").agg(sum(\"Global_Sales\").alias(\"Total_Sales\"))\n",
        "\n",
        "# Calculate the total sales per year for normalization\n",
        "total_yearly_sales = platform_yearly_sales.groupBy(\"Year\").agg(sum(\"Total_Sales\").alias(\"Year_Total\"))\n",
        "\n",
        "# Join to get market share\n",
        "market_share = platform_yearly_sales.join(total_yearly_sales, \"Year\").withColumn(\"Market_Share\", col(\"Total_Sales\") / col(\"Year_Total\"))\n",
        "\n",
        "market_share.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmjVKvjv9blu",
        "outputId": "987ddd3e-2b92-43fa-df41-9419470ebe86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-----------+----------+--------------------+\n",
            "|Year|Platform|Total_Sales|Year_Total|        Market_Share|\n",
            "+----+--------+-----------+----------+--------------------+\n",
            "|1990|     GEN|          2|        43|0.046511627906976744|\n",
            "|1990|     NES|         13|        43|  0.3023255813953488|\n",
            "|1990|    SNES|         24|        43|  0.5581395348837209|\n",
            "|1990|      GB|          4|        43| 0.09302325581395349|\n",
            "|2003|      PS|          1|       159|0.006289308176100629|\n",
            "|2003|     GBA|         24|       159|  0.1509433962264151|\n",
            "|2003|     PS2|         93|       159|  0.5849056603773585|\n",
            "|2003|      GC|         20|       159| 0.12578616352201258|\n",
            "|2003|      PC|          5|       159|0.031446540880503145|\n",
            "|2003|      XB|         16|       159| 0.10062893081761007|\n",
            "|2007|      DC|          0|       332|                 0.0|\n",
            "|2007|     PSP|         17|       332| 0.05120481927710843|\n",
            "|2007|      DS|         73|       332| 0.21987951807228914|\n",
            "|2007|      PC|          6|       332|0.018072289156626505|\n",
            "|2007|    X360|         57|       332|  0.1716867469879518|\n",
            "|2007|     PS3|         44|       332| 0.13253012048192772|\n",
            "|2007|      GC|          0|       332|                 0.0|\n",
            "|2007|     Wii|        105|       332| 0.31626506024096385|\n",
            "|2007|     GBA|          2|       332|0.006024096385542169|\n",
            "|2007|      XB|          0|       332|                 0.0|\n",
            "+----+--------+-----------+----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col, sum as _sum\n",
        "\n",
        "# Step 1: Aggregate sales by year and genre\n",
        "year_genre_sales = df.groupBy(\"Year\", \"Genre\").agg(_sum(\"Global_Sales\").alias(\"Total_Sales\"))\n",
        "\n",
        "# Step 2: Use a window function to rank genres within each year by Total_Sales\n",
        "windowSpec = Window.partitionBy(\"Year\").orderBy(col(\"Total_Sales\").desc())\n",
        "\n",
        "# Apply the window specification to add a rank column\n",
        "ranked_year_genre_sales = year_genre_sales.withColumn(\"Rank\", rank().over(windowSpec))\n",
        "\n",
        "# Filter to get only the top genre of each year (rank = 1)\n",
        "top_genre_per_year = ranked_year_genre_sales.filter(col(\"Rank\") == 1).orderBy(\"Year\")\n",
        "\n",
        "# Show the result\n",
        "top_genre_per_year.select(\"Year\", \"Genre\").show(39)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Nyqnn1oAh0",
        "outputId": "8b55c18d-a2c4-4b15-a75f-762aacc98368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+------------+\n",
            "|Year|       Genre|\n",
            "+----+------------+\n",
            "|NULL|      Action|\n",
            "|1980|     Shooter|\n",
            "|1981|     Shooter|\n",
            "|1982|      Puzzle|\n",
            "|1983|    Platform|\n",
            "|1984|     Shooter|\n",
            "|1985|    Platform|\n",
            "|1986|      Action|\n",
            "|1987|    Fighting|\n",
            "|1988|    Platform|\n",
            "|1989|      Puzzle|\n",
            "|1990|    Platform|\n",
            "|1991|    Platform|\n",
            "|1991|      Action|\n",
            "|1992|    Fighting|\n",
            "|1993|    Platform|\n",
            "|1994|    Platform|\n",
            "|1995|    Platform|\n",
            "|1996|Role-Playing|\n",
            "|1997|      Racing|\n",
            "|1998|      Action|\n",
            "|1999|Role-Playing|\n",
            "|2000|      Action|\n",
            "|2001|      Action|\n",
            "|2002|      Action|\n",
            "|2003|      Action|\n",
            "|2004|      Action|\n",
            "|2005|  Simulation|\n",
            "|2006|      Sports|\n",
            "|2007|        Misc|\n",
            "|2008|      Action|\n",
            "|2009|      Sports|\n",
            "|2010|      Action|\n",
            "|2011|     Shooter|\n",
            "|2012|      Action|\n",
            "|2013|      Action|\n",
            "|2014|      Action|\n",
            "|2015|     Shooter|\n",
            "|2016|     Shooter|\n",
            "+----+------------+\n",
            "only showing top 39 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import rank, col, sum as _sum\n",
        "\n",
        "# Step 1: Aggregate sales by year and Platform\n",
        "year_Platform_sales = df.groupBy(\"Year\", \"Platform\").agg(_sum(\"Global_Sales\").alias(\"Total_Sales\"))\n",
        "\n",
        "# Step 2: Use a window function to rank Platform within each year by Total_Sales\n",
        "windowSpec = Window.partitionBy(\"Year\").orderBy(col(\"Total_Sales\").desc())\n",
        "\n",
        "# Apply the window specification to add a rank column\n",
        "ranked_year_Platform_sales = year_Platform_sales.withColumn(\"Rank\", rank().over(windowSpec))\n",
        "\n",
        "# Filter to get only the top Platform of each year (rank = 1)\n",
        "top_Platform_per_year = ranked_year_Platform_sales.filter(col(\"Rank\") == 1).orderBy(\"Year\")\n",
        "\n",
        "# Show the result\n",
        "top_Platform_per_year.select(\"Year\", \"Platform\",\"Total_Sales\").show(38)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9FdzC2EoGqY",
        "outputId": "d53b69d1-253d-441c-e537-d103729f954e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+-----------+\n",
            "|Year|Platform|Total_Sales|\n",
            "+----+--------+-----------+\n",
            "|NULL|     PS2|         13|\n",
            "|1980|    2600|          8|\n",
            "|1981|    2600|         16|\n",
            "|1982|    2600|         13|\n",
            "|1983|     NES|         10|\n",
            "|1984|     NES|         45|\n",
            "|1985|     NES|         49|\n",
            "|1986|     NES|         28|\n",
            "|1987|     NES|         15|\n",
            "|1988|     NES|         40|\n",
            "|1989|      GB|         61|\n",
            "|1990|    SNES|         24|\n",
            "|1991|    SNES|          8|\n",
            "|1992|    SNES|         25|\n",
            "|1993|    SNES|         24|\n",
            "|1994|    SNES|         16|\n",
            "|1995|    SNES|         20|\n",
            "|1996|      PS|         49|\n",
            "|1997|      PS|         82|\n",
            "|1998|      PS|         98|\n",
            "|1999|      PS|         76|\n",
            "|2000|      PS|         47|\n",
            "|2001|     PS2|        107|\n",
            "|2002|     PS2|        119|\n",
            "|2003|     PS2|         93|\n",
            "|2004|     PS2|        123|\n",
            "|2005|      DS|        109|\n",
            "|2006|     Wii|        125|\n",
            "|2007|     Wii|        105|\n",
            "|2008|     Wii|         95|\n",
            "|2009|     Wii|        123|\n",
            "|2010|    X360|        116|\n",
            "|2011|     PS3|         95|\n",
            "|2012|    X360|         63|\n",
            "|2013|     PS3|         78|\n",
            "|2014|     PS4|         70|\n",
            "|2015|     PS4|         77|\n",
            "|2016|     PS4|         21|\n",
            "+----+--------+-----------+\n",
            "only showing top 38 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Predictive Modeling for Global Sales\n"
      ],
      "metadata": {
        "id": "YNudVPa-pN1o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use a linear regression model from PySpark's MLlib to predict global sales based on the platform, genre, and regional sales (NA_Sales, EU_Sales, JP_Sales, Other_Sales). This example requires numerical features, so we'll need to convert categorical features (Genre, Platform) into numerical form using one-hot encoding."
      ],
      "metadata": {
        "id": "yl-S8yhEpRU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LinearRegression"
      ],
      "metadata": {
        "id": "2ycwroy7qa02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Indexing categorical columns to prepare for OneHotEncoding\n",
        "indexers = [\n",
        "    StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df)\n",
        "    for column in ['Platform', 'Genre']\n",
        "]\n",
        "\n",
        "# OneHotEncoding indexed columns\n",
        "encoders = [\n",
        "    OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=indexer.getOutputCol()+\"_vec\")\n",
        "    for indexer in indexers\n",
        "]\n",
        "\n",
        "# Assembling features\n",
        "assemblerInputs = [encoder.getOutputCol() for encoder in encoders] + ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales']\n",
        "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
        "\n",
        "# Linear Regression model\n",
        "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Global_Sales\")\n",
        "\n",
        "# Pipeline\n",
        "pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n",
        "\n",
        "# Splitting data into training and test sets\n",
        "(trainingData, testData) = df.randomSplit([0.7, 0.3])\n"
      ],
      "metadata": {
        "id": "muh0YxDepO0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on training data\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Select example rows to display\n",
        "predictions.select(\"prediction\", \"Global_Sales\", \"features\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwUf1erlpZYc",
        "outputId": "9afb31b4-b091-49fb-a194-7005e49a9cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------+--------------------+\n",
            "|        prediction|Global_Sales|            features|\n",
            "+------------------+------------+--------------------+\n",
            "| 33.72931651712838|          33|(45,[3,31,41,42,4...|\n",
            "| 32.74682892191595|          31|(45,[20,33,41,42,...|\n",
            "|   32.421735946817|          30|(45,[20,41,42,43]...|\n",
            "| 29.46563733307112|          28|(45,[21,34,41],[1...|\n",
            "|22.841130460946864|          23|(45,[0,36,41,42,4...|\n",
            "+------------------+------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select example rows to display\n",
        "predictions.select(\"prediction\", \"Global_Sales\", \"features\").show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbAYdPOaph7Z",
        "outputId": "65c73521-8fad-44b3-ea35-bb37651b30b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+------------+--------------------+\n",
            "|        prediction|Global_Sales|            features|\n",
            "+------------------+------------+--------------------+\n",
            "| 33.72931651712838|          33|(45,[3,31,41,42,4...|\n",
            "| 32.74682892191595|          31|(45,[20,33,41,42,...|\n",
            "|   32.421735946817|          30|(45,[20,41,42,43]...|\n",
            "| 29.46563733307112|          28|(45,[21,34,41],[1...|\n",
            "|22.841130460946864|          23|(45,[0,36,41,42,4...|\n",
            "| 22.56358969418175|          22|(45,[3,31,41,42,4...|\n",
            "| 21.88111199194859|          22|(45,[3,31,41,42,4...|\n",
            "| 20.00299606151171|          20|(45,[15,37,41,42,...|\n",
            "|14.907515033281516|          15|(45,[0,41,42,43,4...|\n",
            "| 14.19085664153037|          14|(45,[1,36,41,42,4...|\n",
            "+------------------+------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Evaluate model\n",
        "evaluator = RegressionEvaluator(\n",
        "    labelCol=\"Global_Sales\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root Mean Squared Error (RMSE) on test data =\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqY8yytJpbEI",
        "outputId": "57ec6d56-e5c3-430d-9006-8725375bb5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on test data = 0.2995882531776655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Root Mean Squared Error (RMSE) of approximately 0.2996 indicates the model's average error in predicting the global sales figures. Given that sales figures can vary significantly, an RMSE of this magnitude suggests that the model has a reasonable level of accuracy. However, the performance could vary based on the scale of global sales; for games with very high sales figures, an RMSE of 0.3 might represent a relatively small error, while for games with lower sales figures, it might represent a larger proportion of the actual sales figure."
      ],
      "metadata": {
        "id": "w3dp3wETpzQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Predictive Modeling for Other Targets\n",
        "Let's predict whether a game will be a hit in the North American market (NA_Sales greater than a certain threshold, e.g., the top 25% of games sold). This requires creating a binary label and building a classification model."
      ],
      "metadata": {
        "id": "oS8MZ2mcsYDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "# Calculate the sales threshold for the top 25% of games in NA_Sales\n",
        "sales_threshold = df.approxQuantile(\"NA_Sales\", [0.75], 0)[0]\n",
        "\n",
        "# Create a new binary column 'label' indicating whether a game is a hit in NA\n",
        "df = df.withColumn(\"label\", when(col(\"NA_Sales\") > sales_threshold, 1).otherwise(0))\n",
        "\n",
        "# Prepare features (using StringIndexer for categorical features like 'Platform' and 'Genre')\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in ['Platform', 'Genre']]\n",
        "assembler = VectorAssembler(inputCols=[indexer.getOutputCol() for indexer in indexers] + ['EU_Sales', 'JP_Sales', 'Other_Sales'], outputCol=\"features\")\n"
      ],
      "metadata": {
        "id": "V3gNAf6HtUAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Define the classifier\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "# Combine steps into a Pipeline\n",
        "pipeline = Pipeline(stages=indexers + [assembler, rf])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "(train_data, test_data) = df.randomSplit([0.8, 0.2])\n",
        "\n",
        "# Train the model\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(test_data)\n"
      ],
      "metadata": {
        "id": "2KillkZ5tVjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "auc = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Area Under ROC: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yej8sk_0tXS-",
        "outputId": "dcac301e-a47a-4d9b-bc86-9f91411bf00f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Area Under ROC: 0.7943315411946615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Evaluate model\n",
        "evaluator = BinaryClassificationEvaluator()\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7H0D_N7tmKC",
        "outputId": "c13b0959-dd62-4e74-e4a5-365bec7b9e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7943315411946615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select('Name', 'NA_Sales', 'label', 'prediction').show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15OFE5LFtYyY",
        "outputId": "22e8b0d3-88f2-4df7-c546-b0c6b644e829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+-----+----------+\n",
            "|                Name|NA_Sales|label|prediction|\n",
            "+--------------------+--------+-----+----------+\n",
            "|Grand Theft Auto:...|       9|    1|       0.0|\n",
            "|  Grand Theft Auto V|       9|    1|       1.0|\n",
            "|  Grand Theft Auto V|       3|    1|       1.0|\n",
            "|The Legend of Zel...|       4|    1|       1.0|\n",
            "|Metal Gear Solid ...|       2|    1|       1.0|\n",
            "| Batman: Arkham City|       2|    1|       1.0|\n",
            "|The Legend of Zel...|       1|    1|       1.0|\n",
            "|       Resident Evil|       2|    1|       1.0|\n",
            "|         Tomb Raider|       2|    1|       1.0|\n",
            "|The Legend of Zel...|       2|    1|       0.0|\n",
            "+--------------------+--------+-----+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results from predictive model show a table with the game names (Name), their North American sales figures (NA_Sales), the actual label indicating whether the game was a hit (label), and the model's prediction of whether it classified the game as a hit (prediction).\n",
        "\n",
        "Name: The name of the video game.\n",
        "NA_Sales: The sales figures for the game in North America.\n",
        "label: The actual classification of the game based on your definition of a hit (1 for hit, 0 for not a hit). In this context, a game labeled as 1 means it's among the top 25% of games by NA_Sales.\n",
        "prediction: The model's prediction of whether the game is a hit (1.0 for hit, 0.0 for not a hit) based on the features provided to the model.\n",
        "From the results:\n",
        "\n",
        "Correct Predictions: When the label matches the prediction, it indicates a correct prediction by the model. For example, \"Grand Theft Auto V\" with NA_Sales of 9 and \"The Legend of Zelda: Breath of the Wild\" with NA_Sales of 4 are correctly identified as hits (label 1 and prediction 1.0).\n",
        "\n",
        "Incorrect Predictions: When the label does not match the prediction, it indicates an incorrect prediction. For example, \"Grand Theft Auto: San Andreas\" and the last entry for \"The Legend of Zelda\" show that despite being actual hits (label 1), they were predicted not to be hits (prediction 0.0)."
      ],
      "metadata": {
        "id": "G-s2nVZtttLL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Strengths: The model seems capable of correctly identifying certain hit games as hits, which suggests it has learned some patterns or relationships in the data that correlate with a game being a hit"
      ],
      "metadata": {
        "id": "OljXcMVht0TX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Clustering Analysis"
      ],
      "metadata": {
        "id": "H9po0Fu0qWKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Assemble sales data into feature vectors\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\"],\n",
        "    outputCol=\"features\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "RVyKzQ8mqWUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize KMeans with a specified number of clusters\n",
        "kmeans = KMeans().setK(5).setSeed(1).setFeaturesCol(\"features\")\n"
      ],
      "metadata": {
        "id": "4eThOLFaqfwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline\n",
        "pipeline = Pipeline(stages=[assembler, kmeans])\n",
        "\n",
        "# Fit the model\n",
        "model = pipeline.fit(df)\n"
      ],
      "metadata": {
        "id": "8b8FpEnwqhQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign games to clusters\n",
        "predictions = model.transform(df)\n",
        "\n",
        "# Show cluster assignments\n",
        "predictions.select(\"Name\", \"NA_Sales\", \"EU_Sales\", \"JP_Sales\", \"Other_Sales\", \"prediction\").show()\n",
        "\n",
        "# Evaluate clustering by computing Within Set Sum of Squared Errors\n",
        "wssse = model.stages[-1].computeCost(predictions)\n",
        "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "gQtiHMlCqjai",
        "outputId": "bd7ff01e-38b9-4499-e08e-545604b1514f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------+--------+--------+-----------+----------+\n",
            "|                Name|NA_Sales|EU_Sales|JP_Sales|Other_Sales|prediction|\n",
            "+--------------------+--------+--------+--------+-----------+----------+\n",
            "|          Wii Sports|      41|      29|       3|          8|         1|\n",
            "|   Super Mario Bros.|      29|       3|       6|          0|         1|\n",
            "|      Mario Kart Wii|      15|      12|       3|          3|         2|\n",
            "|   Wii Sports Resort|      15|      11|       3|          2|         2|\n",
            "|Pokemon Red/Pokem...|      11|       8|      10|          1|         2|\n",
            "|              Tetris|      23|       2|       4|          0|         1|\n",
            "|New Super Mario B...|      11|       9|       6|          2|         2|\n",
            "|            Wii Play|      14|       9|       2|          2|         2|\n",
            "|New Super Mario B...|      14|       7|       4|          2|         2|\n",
            "|           Duck Hunt|      26|       0|       0|          0|         1|\n",
            "|          Nintendogs|       9|      11|       1|          2|         2|\n",
            "|       Mario Kart DS|       9|       7|       4|          1|         2|\n",
            "|Pokemon Gold/Poke...|       9|       6|       7|          0|         2|\n",
            "|             Wii Fit|       8|       8|       3|          2|         2|\n",
            "|        Wii Fit Plus|       9|       8|       2|          1|         2|\n",
            "|  Kinect Adventures!|      14|       4|       0|          1|         2|\n",
            "|  Grand Theft Auto V|       7|       9|       0|          4|         2|\n",
            "|Grand Theft Auto:...|       9|       0|       0|         10|         3|\n",
            "|   Super Mario World|      12|       3|       3|          0|         2|\n",
            "|Brain Age: Train ...|       4|       9|       4|          2|         2|\n",
            "+--------------------+--------+--------+--------+-----------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'KMeansModel' object has no attribute 'computeCost'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-cfb57c00723d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Evaluate clustering by computing Within Set Sum of Squared Errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mwssse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeCost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Within Set Sum of Squared Errors = \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwssse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KMeansModel' object has no attribute 'computeCost'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "\n",
        "# Create a ClusteringEvaluator instance with silhouette metric\n",
        "evaluator = ClusteringEvaluator(predictionCol='prediction', featuresCol='features', metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
        "\n",
        "# Evaluate clustering by computing the silhouette score\n",
        "silhouette = evaluator.evaluate(predictions)\n",
        "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mclmNypq0Sz",
        "outputId": "2e0603e2-6dec-462b-bd78-c4e6efc9d2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Silhouette with squared euclidean distance = 0.9683635853840182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "he silhouette score you've obtained, approximately 0.968, indicates a very high degree of separation between the clusters. In the context of clustering analysis, a silhouette score closer to 1 suggests that the clusters are well apart from each other and clearly defined, meaning that games within each cluster have similar sales patterns across different regions, and these patterns are distinct from those in other clusters.\n",
        "\n",
        "Interpretation\n",
        "High Silhouette Score: A silhouette score near 1 is typically very good, suggesting that your clustering model has successfully identified distinct groups of video games based on their sales across different regions.\n",
        "Cluster Quality: The high score implies that each cluster is compact (games within a cluster are similar to each other) and well-separated from other clusters (games from different clusters have dissimilar sales patterns)."
      ],
      "metadata": {
        "id": "g9jBwiC7q_El"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Analyze Cluster Characteristics"
      ],
      "metadata": {
        "id": "ZvRKxsMGrWbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean sales for each cluster\n",
        "mean_sales_by_cluster = predictions.groupBy('prediction').agg(\n",
        "    _sum(\"NA_Sales\").alias(\"Mean_NA_Sales\"),\n",
        "    _sum(\"EU_Sales\").alias(\"Mean_EU_Sales\"),\n",
        "    _sum(\"JP_Sales\").alias(\"Mean_JP_Sales\"),\n",
        "    _sum(\"Other_Sales\").alias(\"Mean_Other_Sales\"),\n",
        "    _sum(\"Global_Sales\").alias(\"Mean_Global_Sales\")\n",
        ").orderBy(\"prediction\")\n",
        "\n",
        "mean_sales_by_cluster.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q5DwK3JrX20",
        "outputId": "d8b451be-6756-4d8b-a2f0-f76d8a59e864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+-------------+-------------+----------------+-----------------+\n",
            "|prediction|Mean_NA_Sales|Mean_EU_Sales|Mean_JP_Sales|Mean_Other_Sales|Mean_Global_Sales|\n",
            "+----------+-------------+-------------+-------------+----------------+-----------------+\n",
            "|         0|          564|          245|          197|              22|             2426|\n",
            "|         1|          119|           34|           13|               8|              180|\n",
            "|         2|          283|          193|           88|              38|              648|\n",
            "|         3|           12|            0|            1|              17|               31|\n",
            "|         4|          785|          365|          107|              37|             1595|\n",
            "+----------+-------------+-------------+-------------+----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import mean\n",
        "\n",
        "# Aggregate mean sales by cluster\n",
        "mean_sales_by_cluster = predictions.groupBy(\"prediction\").agg(\n",
        "    mean(\"NA_Sales\").alias(\"Mean_NA_Sales\"),\n",
        "    mean(\"EU_Sales\").alias(\"Mean_EU_Sales\"),\n",
        "    mean(\"JP_Sales\").alias(\"Mean_JP_Sales\"),\n",
        "    mean(\"Other_Sales\").alias(\"Mean_Other_Sales\"),\n",
        "    mean(\"Global_Sales\").alias(\"Mean_Global_Sales\")\n",
        ")\n",
        "\n",
        "# Order the results by cluster id\n",
        "ordered_mean_sales_by_cluster = mean_sales_by_cluster.orderBy(\"prediction\")\n"
      ],
      "metadata": {
        "id": "NxU83Knjrijl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the mean sales for each cluster\n",
        "ordered_mean_sales_by_cluster.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gkpmOsmrm9x",
        "outputId": "622ff8a3-6a62-4618-a87f-1cdbb79c8ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
            "|prediction|       Mean_NA_Sales|       Mean_EU_Sales|       Mean_JP_Sales|    Mean_Other_Sales|  Mean_Global_Sales|\n",
            "+----------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
            "|         0|0.034714101064811966|0.015079707022834985|0.012125315442850988|0.001354096140825...|0.14931987443835784|\n",
            "|         1|               29.75|                 8.5|                3.25|                 2.0|               45.0|\n",
            "|         2|   8.575757575757576|   5.848484848484849|  2.6666666666666665|  1.1515151515151516| 19.636363636363637|\n",
            "|         3|                 6.0|                 0.0|                 0.5|                 8.5|               15.5|\n",
            "|         4|   2.516025641025641|   1.169871794871795| 0.34294871794871795| 0.11858974358974358|  5.112179487179487|\n",
            "+----------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " table similar to the one you provided, where each row corresponds to a cluster, and the columns represent the mean sales for North America, Europe, Japan, Other regions, and globally. The table helps to interpret the characteristics of each cluster, such as which clusters represent games with high sales in specific regions or globally."
      ],
      "metadata": {
        "id": "6DqXOJ-qryHe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The table shows the mean sales for each cluster across different regions (NA, EU, JP, Other) and globally. This data provides insights into different market segments represented by each cluster:\n",
        "\n",
        "Cluster 0 appears to represent a large group of games with relatively low sales across all regions, suggesting these might be niche titles or games that didn't achieve widespread popularity.\n",
        "\n",
        "Cluster 1 stands out with significantly higher average sales in all regions, especially in North America (NA) and Europe (EU). This cluster likely includes blockbuster titles or highly popular franchises.\n",
        "\n",
        "Cluster 2 represents games with moderate success, having decent sales figures across NA and EU, and somewhat lower, yet significant, sales in Japan (JP). These could be well-received games that didn't reach the blockbuster status of Cluster 1 but still performed well.\n",
        "\n",
        "Cluster 3 is peculiar with very high Other sales and decent NA sales but virtually no presence in EU and JP. This cluster might include games that were popular in markets outside the traditional gaming centers or had specific regional appeal.\n",
        "\n",
        "Cluster 4 includes games with modest sales across all regions, likely representing average performers in the market."
      ],
      "metadata": {
        "id": "jQ88Haknr04x"
      }
    }
  ]
}